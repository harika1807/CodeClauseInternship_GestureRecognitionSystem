
# âœ‹ Gesture Recognition System

![Banner](https://raw.githubusercontent.com/harika1807/CodeClauseInternship_GestureRecognitionSystem/main/banner.png)
![License](https://img.shields.io/github/license/harika1807/CodeClauseInternship_GestureRecognitionSystem)

This project is part of the **CodeClause AI Internship (Golden Level)** and focuses on building a real-time **hand gesture recognition system** using deep learning and computer vision.

---

## ğŸ“‚ Dataset

We used a subset of the **HaGRID (HAnd Gesture Recognition Image Dataset)**, extracting five gestures:
- âœŠ Fist  
- âœ‹ Palm  
- ğŸ‘ Thumbs Up  
- ğŸ‘ Thumbs Down  
- âœŒï¸ Victory (Peace)

Dataset organized into:
```
dataset/
â”œâ”€â”€ fist/
â”œâ”€â”€ palm/
â”œâ”€â”€ thumb_up/
â”œâ”€â”€ thumb_down/
â””â”€â”€ victory/
```

Each folder contains respective gesture images, and `hagrid_labels.csv` maps image paths to labels.

---

## ğŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/harika1807/CodeClauseInternship_GestureRecognitionSystem
   cd CodeClauseInternship_GestureRecognitionSystem
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“† Requirements

```
tensorflow==2.11.0
opencv-python==4.8.0.76
numpy==1.23.5
pandas==1.5.3
matplotlib==3.6.2
scikit-learn==1.2.0
```

---

## ğŸ§  Model Training

To train the CNN model:
```bash
python gesture_recognition_model.py
```

- Trains a Convolutional Neural Network using the dataset.
- Saves the model as `gesture_recognition_model.h5`.

---

## ğŸ“Š Training Results

#### ğŸ”¹ Model Accuracy
![Model Accuracy](https://github.com/harika1807/CodeClauseInternship_GestureRecognitionSystem/blob/main/model_accuracy.png)

#### ğŸ”¹ Model Loss
![Model Loss](https://github.com/harika1807/CodeClauseInternship_GestureRecognitionSystem/blob/main/model_loss.png)

---

## ğŸ“¸ Real-Time Gesture Recognition

To launch the real-time gesture detection using webcam:
```bash
python gesture_recognition_live.py
```

- Loads the trained `.h5` model.
- Detects and classifies hand gestures from the live video feed.
- Saves output as `gesture_output.mp4` in the project folder.

---

## ğŸ–¥ï¸ Output Video

The real-time classification video will be saved as:
```
gesture_output.mp4
```

You can view it with VLC or any media player.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ fist/
â”‚   â”œâ”€â”€ palm/
â”‚   â”œâ”€â”€ thumb_up/
â”‚   â”œâ”€â”€ thumb_down/
â”‚   â””â”€â”€ victory/
â”œâ”€â”€ hagrid_labels.csv
â”œâ”€â”€ gesture_recognition_model.py
â”œâ”€â”€ realtime_gesture_recognition.py
â”œâ”€â”€ gesture_output.mp4
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ’¡ Notes

- To keep the repo lightweight, the trained model (`.h5`) is not included.
- ğŸ“… [Download Gesture Recognition Model (.h5) from Google Drive](https://drive.google.com/file/d/1DycxuFZ1LB3i9zH0W-tjJJaqrqhLuGMS/view?usp=drive_link)

---

## ğŸ‘©â€ğŸ’» Developed by

**Harika Devi**  
B.Tech CSE, Rise Krishna Sai Gandhi Group of Institutions  
ğŸ¯ CodeClause AI Internship (Golden Level)

---

## ğŸ“¬ Contact

ğŸ“§ [harikaseelam2004@gmail.com]  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/harika-devi-seelam-242709256/)
