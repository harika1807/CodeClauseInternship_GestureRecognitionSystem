
# Gesture Recognition System ðŸŽ¯âœ‹ðŸ¤–

![Banner](https://raw.githubusercontent.com/harika1807/CodeClauseInternship_GestureRecognitionSystem/main/banner.png)
![License](https://img.shields.io/github/license/harika1807/CodeClauseInternship_GestureRecognitionSystem)
![Last Commit](https://img.shields.io/github/last-commit/harika1807/CodeClauseInternship_GestureRecognitionSystem)

## ðŸ” Project Overview
A real-time hand gesture recognition system that detects and classifies hand gestures using deep learning and computer vision techniques.

## ðŸŽ¯ Aim
Develop a system that recognizes hand gestures from a video stream or camera feed to enable interactions with digital environments.

## ðŸ› ï¸ Technologies Used
- Python ðŸ
- OpenCV ðŸŽ¥
- TensorFlow/Keras ðŸ¤–
- CNN (Convolutional Neural Networks) ðŸ§ 

## ðŸ“‚ Dataset
This project uses the [HaGRID Dataset](https://github.com/hukenovs/hagrid), a large-scale hand gesture recognition dataset.

## ðŸš€ Features
- Real-time gesture detection via webcam
- Custom trained CNN model using HaGRID
- Classifies 17 hand gestures

## âœ‹ Supported Gestures (with emoji & thumbnail placeholders)

| Gesture           | Emoji | Sample |
|-------------------|-------|--------|
| Call              | ðŸ“ž    | ![call](samples/call.png) |
| Dislike           | ðŸ‘Ž    | ![dislike](samples/dislike.png) |
| Fist              | âœŠ    | ![fist](samples/fist.png) |
| Four              | 4ï¸âƒ£    | ![four](samples/four.png) |
| Like              | ðŸ‘    | ![like](samples/like.png) |
| Mute              | ðŸ¤    | ![mute](samples/mute.png) |
| OK                | ðŸ‘Œ    | ![ok](samples/ok.png) |
| One               | â˜ï¸    | ![one](samples/one.png) |
| Palm              | âœ‹    | ![palm](samples/palm.png) |
| Peace             | âœŒï¸    | ![peace](samples/peace.png) |
| Peace Inverted    | âœŒï¸â¬‡ï¸  | ![peace_inverted](samples/peace_inverted.png) |
| Rock              | ðŸ¤˜    | ![rock](samples/rock.png) |
| Stop              | ðŸ›‘    | ![stop](samples/stop.png) |
| Stop Inverted     | ðŸ›‘â¬‡ï¸  | ![stop_inverted](samples/stop_inverted.png) |
| Three             | 3ï¸âƒ£    | ![three](samples/three.png) |
| Three2            | 3ï¸âƒ£âœŒï¸ | ![three2](samples/three2.png) |
| Two Up            | âœŒï¸â¬†ï¸  | ![two_up](samples/two_up.png) |
| Two Up Inverted   | âœŒï¸â¬‡ï¸  | ![two_up_inverted](samples/two_up_inverted.png) |

## ðŸ–¥ï¸ Usage
1. Clone the repository.
2. Install the dependencies from `requirements.txt`
3. Run the `collect_images.py` script to collect gesture images (if using custom dataset).
4. Run `train_model.py` to train your model.
5. Execute `recognize_gesture.py` for real-time prediction.

## ðŸ“½ï¸ Sample Output
> The `output.avi` shows real-time hand gesture predictions in action.

## ðŸ“œ License
This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.

## ðŸ™Œ Acknowledgments
- [HaGRID Dataset](https://github.com/hukenovs/hagrid)
- CodeClause Internship AI Projects
